{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Part Of Speech`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `Preprocessing`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=pd.read_csv('train_data.csv')\n",
    "test_df=pd.read_csv('test_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of Nulls after splitting for Train Data : headline    3\n",
      "category    0\n",
      "dtype: int64\n",
      "Num of Nulls after splitting for Test Data : headline    0\n",
      "category    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "### Check Nulls after split \n",
    "print('Num of Nulls after splitting for Train Data :', train_df.isna().sum())\n",
    "\n",
    "print('Num of Nulls after splitting for Test Data :', test_df.isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                  Our Most Fearless Tweet Finalist PHOTOS\n",
       "1                                             Hunger Hurts\n",
       "2        Perfect Tweets About Bachelor In Paradise Seas...\n",
       "3                            Nuh Linga Get Down to Jamaica\n",
       "4        Airplane Boneyards Look Even Cooler In Instagr...\n",
       "                               ...                        \n",
       "66312    Osteochondral Ankle Surgery Is This What ShinS...\n",
       "66313                         Americas Most Damaged Brands\n",
       "66314    Grief and Loss Tips on How We Can Help Those A...\n",
       "66315    Beyonce Taylor Swift And Other Celebrities Sen...\n",
       "66316       Hillary President The Elephant in the RoomBill\n",
       "Name: headline, Length: 66314, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['headline']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `POS`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `Spacy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def clean_and_extract_pos(text):\n",
    "    \n",
    "    text = text.lower()  \n",
    "    doc = nlp(text)\n",
    "    # Extract POS tags\n",
    "    pos_tags = [token.pos_ for token in doc]\n",
    "    \n",
    "    return ' '.join(pos_tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['headline']=train_df['headline'].apply(clean_and_extract_pos)\n",
    "test_df['headline']=test_df['headline'].apply(clean_and_extract_pos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "bow_vectorizer = CountVectorizer(analyzer=lambda x: x,max_features=1000)  # We pass the tokenized list directly\n",
    "\n",
    "X_train_pos = bow_vectorizer.fit_transform(train_df['headline'])\n",
    "X_test_pos = bow_vectorizer.transform(test_df['headline'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Implement Models` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score , classification_report\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `Spacy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training SVM with POS Spacy features...\n",
      "Train Accuracy for SVM:\n",
      "0.22284887052507765\n",
      "Test Accuracy for SVM:\n",
      "0.22165259348612787\n",
      "Precision for SVM:\n",
      "0.22849996454029273\n",
      "Recall for SVM:\n",
      "0.22165259348612787\n",
      "Classification Report for SVM:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.06      0.08      1195\n",
      "           1       0.28      0.16      0.20      2000\n",
      "           2       0.17      0.38      0.23      1266\n",
      "           3       0.19      0.12      0.14      2000\n",
      "           4       0.28      0.15      0.20      2000\n",
      "           5       0.17      0.15      0.16      1267\n",
      "           6       0.12      0.20      0.15      1015\n",
      "           7       0.29      0.32      0.30      1863\n",
      "           8       0.26      0.21      0.23      1974\n",
      "           9       0.27      0.42      0.33      2000\n",
      "\n",
      "    accuracy                           0.22     16580\n",
      "   macro avg       0.21      0.22      0.20     16580\n",
      "weighted avg       0.23      0.22      0.21     16580\n",
      "\n",
      "\n",
      "Training Naive Bayes with POS Spacy features...\n",
      "Train Accuracy for Naive Bayes:\n",
      "0.2134541725729107\n",
      "Test Accuracy for Naive Bayes:\n",
      "0.21302774427020507\n",
      "Precision for Naive Bayes:\n",
      "0.1665812403290275\n",
      "Recall for Naive Bayes:\n",
      "0.21302774427020507\n",
      "Classification Report for Naive Bayes:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.00      0.00      1195\n",
      "           1       0.22      0.33      0.26      2000\n",
      "           2       0.15      0.01      0.02      1266\n",
      "           3       0.12      0.03      0.05      2000\n",
      "           4       0.24      0.26      0.25      2000\n",
      "           5       0.00      0.00      0.00      1267\n",
      "           6       0.00      0.00      0.00      1015\n",
      "           7       0.25      0.22      0.23      1863\n",
      "           8       0.19      0.28      0.23      1974\n",
      "           9       0.21      0.65      0.32      2000\n",
      "\n",
      "    accuracy                           0.21     16580\n",
      "   macro avg       0.15      0.18      0.14     16580\n",
      "weighted avg       0.17      0.21      0.16     16580\n",
      "\n",
      "\n",
      "Training Neural Network with POS Spacy features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\20100\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\20100\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\20100\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\20100\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy for Neural Network:\n",
      "0.3227071206683355\n",
      "Test Accuracy for Neural Network:\n",
      "0.2425211097708082\n",
      "Precision for Neural Network:\n",
      "0.2281703730705509\n",
      "Recall for Neural Network:\n",
      "0.2425211097708082\n",
      "Classification Report for Neural Network:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.05      0.08      1195\n",
      "           1       0.23      0.36      0.28      2000\n",
      "           2       0.25      0.16      0.19      1266\n",
      "           3       0.16      0.15      0.15      2000\n",
      "           4       0.22      0.28      0.25      2000\n",
      "           5       0.18      0.09      0.12      1267\n",
      "           6       0.12      0.02      0.03      1015\n",
      "           7       0.30      0.32      0.31      1863\n",
      "           8       0.25      0.36      0.30      1974\n",
      "           9       0.31      0.38      0.34      2000\n",
      "\n",
      "    accuracy                           0.24     16580\n",
      "   macro avg       0.22      0.22      0.20     16580\n",
      "weighted avg       0.23      0.24      0.22     16580\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def create_pipeline(model):\n",
    "    return Pipeline([\n",
    "        ('classifier', model)\n",
    "    ])\n",
    "\n",
    "# Models with updated parameters\n",
    "models = {\n",
    "    'SVM': SVC(kernel='linear', C=10, class_weight='balanced'),  \n",
    "    'Naive Bayes': MultinomialNB(alpha=0.01, fit_prior=True),    \n",
    "    'Neural Network': MLPClassifier(hidden_layer_sizes=(128, 64), activation='relu', alpha=0.0001, max_iter=1000)  \n",
    "}\n",
    "\n",
    "output_dir = \"POS_Spacy_Models/\"\n",
    "\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\nTraining {model_name} with POS Spacy features...\")\n",
    "    \n",
    "    \n",
    "    model_pipeline = create_pipeline(model)\n",
    "    \n",
    "    # Train the model\n",
    "    model_pipeline.fit(X_train_pos, train_df['category'])\n",
    "\n",
    "    # Make predictions on the train set\n",
    "    y_pred_train = model_pipeline.predict(X_train_pos)\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    y_pred_test = model_pipeline.predict(X_test_pos)\n",
    "\n",
    "    # Train Accuracy \n",
    "    print(f\"Train Accuracy for {model_name}:\")\n",
    "    print(accuracy_score(train_df['category'], y_pred_train))\n",
    "    \n",
    "    # Test Accuracy\n",
    "    print(f\"Test Accuracy for {model_name}:\")\n",
    "    print(accuracy_score(test_df['category'], y_pred_test))\n",
    "\n",
    "    # Precision Score\n",
    "    print(f\"Precision for {model_name}:\")\n",
    "    print(precision_score(test_df['category'], y_pred_test, average='weighted'))\n",
    "    \n",
    "    # Recall Score \n",
    "    print(f\"Recall for {model_name}:\")\n",
    "    print(recall_score(test_df['category'], y_pred_test, average='weighted'))\n",
    "\n",
    "    # Classification Report \n",
    "    print(f\"Classification Report for {model_name}:\")\n",
    "    print(classification_report(test_df['category'], y_pred_test))\n",
    "    \n",
    "    # Save Model\n",
    "    model_file_path = f\"{output_dir}{model_name}_pos_spacy_model.pkl\"\n",
    "    joblib.dump(model_pipeline, model_file_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
