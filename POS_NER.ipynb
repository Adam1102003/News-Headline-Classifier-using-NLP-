{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `POS + NER`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=pd.read_csv('train_data.csv')\n",
    "test_df=pd.read_csv('test_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of Nulls after splitting for Train Data : headline    3\n",
      "category    0\n",
      "dtype: int64\n",
      "Num of Nulls after splitting for Test Data : headline    0\n",
      "category    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "### Check Nulls after split \n",
    "print('Num of Nulls after splitting for Train Data :', train_df.isna().sum())\n",
    "\n",
    "print('Num of Nulls after splitting for Test Data :', test_df.isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "headline    0\n",
       "category    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `Combine POS and NER`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def pos_and_ner(headline):\n",
    "    doc = nlp(headline)  \n",
    "    \n",
    "    pos_tags = [token.pos_ for token in doc]  # Extract POS tag\n",
    "\n",
    "    ner_labels = [ent.label_ for ent in doc.ents]  # Extract entity label\n",
    "    \n",
    "    return ' '.join(pos_tags + ner_labels)  # Combine POS and NER labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ner_pos= train_df['headline'].apply(pos_and_ner)\n",
    "\n",
    "test_ner_pos= test_df['headline'].apply(pos_and_ner)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "headline\n",
       "PROPN PROPN PROPN                                                                  131\n",
       "PROPN PROPN PROPN PROPN                                                            119\n",
       "PROPN PROPN PROPN PROPN ORG                                                        102\n",
       "PROPN PROPN                                                                         94\n",
       "PROPN PROPN PROPN PROPN PROPN ORG                                                   91\n",
       "                                                                                  ... \n",
       "PRON PRON AUX DET PROPN PROPN PROPN                                                  1\n",
       "INTJ PROPN PROPN PROPN PROPN CCONJ PROPN PROPN ADV PROPN PROPN NOUN                  1\n",
       "PROPN PROPN PROPN AUX PRON PRON PROPN PROPN PROPN PROPN PROPN PROPN AUX ADV ADV      1\n",
       "PROPN CCONJ PROPN PROPN ADP SCONJ PRON AUX VERB DET VERB PERSON                      1\n",
       "PROPN PROPN VERB NOUN ADP PROPN NOUN NORP                                            1\n",
       "Name: count, Length: 57279, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ner_pos.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vectorizer = CountVectorizer()\n",
    "X_train_ner_vectorizer = count_vectorizer.fit_transform(train_ner_pos)\n",
    "X_test_ner_vectorizer = count_vectorizer.transform(test_ner_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Implement Models`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training SVM with NER_POS features...\n",
      "Train Accuracy for SVM:\n",
      "0.2587688874144223\n",
      "Test Accuracy for SVM:\n",
      "0.25820265379975876\n",
      "Percision for SVM:\n",
      "0.24039569839081576\n",
      "Recall for SVM:\n",
      "0.25820265379975876\n",
      " Classification Report for SVM:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.00      0.01      1195\n",
      "           1       0.29      0.38      0.33      2000\n",
      "           2       0.23      0.08      0.12      1266\n",
      "           3       0.16      0.16      0.16      2000\n",
      "           4       0.29      0.32      0.30      2000\n",
      "           5       0.00      0.00      0.00      1267\n",
      "           6       0.28      0.04      0.07      1015\n",
      "           7       0.29      0.33      0.31      1863\n",
      "           8       0.27      0.36      0.31      1974\n",
      "           9       0.25      0.55      0.34      2000\n",
      "\n",
      "    accuracy                           0.26     16580\n",
      "   macro avg       0.24      0.22      0.19     16580\n",
      "weighted avg       0.24      0.26      0.22     16580\n",
      "\n",
      "\n",
      "Training Naive Bayes with NER_POS features...\n",
      "Train Accuracy for Naive Bayes:\n",
      "0.22446240612841933\n",
      "Test Accuracy for Naive Bayes:\n",
      "0.22665862484921592\n",
      "Percision for Naive Bayes:\n",
      "0.1883386923709192\n",
      "Recall for Naive Bayes:\n",
      "0.22665862484921592\n",
      " Classification Report for Naive Bayes:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.01      0.01      1195\n",
      "           1       0.23      0.44      0.31      2000\n",
      "           2       0.06      0.00      0.00      1266\n",
      "           3       0.13      0.03      0.05      2000\n",
      "           4       0.25      0.26      0.25      2000\n",
      "           5       0.00      0.00      0.00      1267\n",
      "           6       0.24      0.05      0.08      1015\n",
      "           7       0.24      0.25      0.25      1863\n",
      "           8       0.24      0.38      0.30      1974\n",
      "           9       0.21      0.51      0.30      2000\n",
      "\n",
      "    accuracy                           0.23     16580\n",
      "   macro avg       0.18      0.19      0.15     16580\n",
      "weighted avg       0.19      0.23      0.18     16580\n",
      "\n",
      "\n",
      "Training Neural Network with NER_POS features...\n",
      "Train Accuracy for Neural Network:\n",
      "0.28446481889193836\n",
      "Test Accuracy for Neural Network:\n",
      "0.27563329312424606\n",
      "Percision for Neural Network:\n",
      "0.2578120093583869\n",
      "Recall for Neural Network:\n",
      "0.27563329312424606\n",
      " Classification Report for Neural Network:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.02      0.04      1195\n",
      "           1       0.27      0.47      0.34      2000\n",
      "           2       0.25      0.18      0.21      1266\n",
      "           3       0.19      0.11      0.14      2000\n",
      "           4       0.27      0.38      0.31      2000\n",
      "           5       0.16      0.02      0.04      1267\n",
      "           6       0.28      0.03      0.05      1015\n",
      "           7       0.33      0.33      0.33      1863\n",
      "           8       0.31      0.35      0.33      1974\n",
      "           9       0.28      0.50      0.36      2000\n",
      "\n",
      "    accuracy                           0.28     16580\n",
      "   macro avg       0.25      0.24      0.22     16580\n",
      "weighted avg       0.26      0.28      0.24     16580\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "def create_pipeline(model):\n",
    "    return Pipeline([\n",
    "        ('classifier', model)\n",
    "    ])\n",
    "\n",
    "# Models\n",
    "models = {\n",
    "    'SVM': SVC(kernel='linear',C=10),\n",
    "    'Naive Bayes': MultinomialNB(alpha=0.5),\n",
    "    'Neural Network': MLPClassifier(hidden_layer_sizes=(50,25), activation='relu', solver='adam', max_iter=500, alpha=0.001,early_stopping=True)\n",
    "}\n",
    "\n",
    "output_dir = \"NER_POS_Models/\"\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\nTraining {model_name} with NER_POS features...\")\n",
    "    \n",
    "    \n",
    "    model_pipeline = create_pipeline(model)\n",
    "    \n",
    "    # Train the model\n",
    "    model_pipeline.fit(X_train_ner_vectorizer, train_df['category'])\n",
    "\n",
    "    # Make predictions on the train set\n",
    "    y_pred_train = model_pipeline.predict(X_train_ner_vectorizer)\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    y_pred_test = model_pipeline.predict(X_test_ner_vectorizer)\n",
    "\n",
    "    # Train Accuracy \n",
    "    print(f\"Train Accuracy for {model_name}:\")\n",
    "    print(accuracy_score(train_df['category'], y_pred_train))\n",
    "    \n",
    "    # Test Accuracy\n",
    "    print(f\"Test Accuracy for {model_name}:\")\n",
    "    print(accuracy_score(test_df['category'], y_pred_test))\n",
    "\n",
    "    # Percision Score\n",
    "    print(f\"Percision for {model_name}:\")\n",
    "    print(precision_score(test_df['category'], y_pred_test,average='weighted'))\n",
    "    \n",
    "    # Recall Score \n",
    "    print(f\"Recall for {model_name}:\")\n",
    "    print(recall_score(test_df['category'], y_pred_test,average='weighted'))\n",
    "\n",
    "    # Classification Report \n",
    "    print(f\" Classification Report for {model_name}:\")\n",
    "    print(classification_report(test_df['category'], y_pred_test))\n",
    "    \n",
    "    # Save Model\n",
    "    model_file_path = f\"{output_dir}{model_name}_ner_pos_model.pkl\"\n",
    "    joblib.dump(model_pipeline, model_file_path)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
