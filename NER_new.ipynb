{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `NER`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Preprocessing`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=pd.read_csv('train_data.csv')\n",
    "test_df=pd.read_csv('test_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of Nulls after splitting for Train Data : headline    3\n",
      "category    0\n",
      "dtype: int64\n",
      "Num of Nulls after splitting for Test Data : headline    0\n",
      "category    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "### Check Nulls after split \n",
    "print('Num of Nulls after splitting for Train Data :', train_df.isna().sum())\n",
    "\n",
    "print('Num of Nulls after splitting for Test Data :', test_df.isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "headline    0\n",
       "category    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `NER Features`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def ner_features(headline):\n",
    "    doc = nlp(headline)  \n",
    "    ner_labels = ' '.join(ent.label_ for ent in doc.ents)\n",
    "    return ner_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ner= train_df['headline'].apply(ner_features)\n",
    "\n",
    "test_ner= test_df['headline'].apply(ner_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vectorizer = CountVectorizer()\n",
    "X_train_ner_vectorizer = count_vectorizer.fit_transform(train_ner)\n",
    "X_test_ner_vectorizer = count_vectorizer.transform(test_ner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66314, 18)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_ner_vectorizer.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `NER Words Only`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def ner_words(headline):\n",
    "    doc = nlp(headline)  \n",
    "    ner_entities = [ent.text for ent in doc.ents]  # Extract the entity words\n",
    "    return ' '.join(ner_entities)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ner= train_df['headline'].apply(ner_words)\n",
    "\n",
    "test_ner= test_df['headline'].apply(ner_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vectorizer = CountVectorizer()\n",
    "X_train_ner_vectorizer2 = count_vectorizer.fit_transform(train_ner)\n",
    "X_test_ner_vectorizer2 = count_vectorizer.transform(test_ner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Implement Models`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `NER Features`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training SVM with NER features...\n",
      "Train Accuracy for SVM:\n",
      "0.21215731218143982\n",
      "Test Accuracy for SVM:\n",
      "0.21242460796139928\n",
      "Percision for SVM:\n",
      "0.16531025593891369\n",
      "Recall for SVM:\n",
      "0.21242460796139928\n",
      " Classification Report for SVM:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1195\n",
      "           1       0.24      0.43      0.30      2000\n",
      "           2       0.00      0.00      0.00      1266\n",
      "           3       0.13      0.04      0.06      2000\n",
      "           4       0.27      0.21      0.24      2000\n",
      "           5       0.00      0.00      0.00      1267\n",
      "           6       0.21      0.04      0.07      1015\n",
      "           7       0.24      0.01      0.02      1863\n",
      "           8       0.19      0.41      0.26      1974\n",
      "           9       0.20      0.65      0.31      2000\n",
      "\n",
      "    accuracy                           0.21     16580\n",
      "   macro avg       0.15      0.18      0.13     16580\n",
      "weighted avg       0.17      0.21      0.15     16580\n",
      "\n",
      "\n",
      "Training Naive Bayes with NER features...\n",
      "Train Accuracy for Naive Bayes:\n",
      "0.1519588623820008\n",
      "Test Accuracy for Naive Bayes:\n",
      "0.15283474065138722\n",
      "Percision for Naive Bayes:\n",
      "0.16019060850422132\n",
      "Recall for Naive Bayes:\n",
      "0.15283474065138722\n",
      " Classification Report for Naive Bayes:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1195\n",
      "           1       0.23      0.50      0.32      2000\n",
      "           2       0.00      0.00      0.00      1266\n",
      "           3       0.17      0.02      0.03      2000\n",
      "           4       0.09      0.30      0.14      2000\n",
      "           5       0.00      0.00      0.00      1267\n",
      "           6       0.38      0.02      0.03      1015\n",
      "           7       0.21      0.01      0.03      1863\n",
      "           8       0.34      0.19      0.25      1974\n",
      "           9       0.12      0.24      0.16      2000\n",
      "\n",
      "    accuracy                           0.15     16580\n",
      "   macro avg       0.15      0.13      0.09     16580\n",
      "weighted avg       0.16      0.15      0.11     16580\n",
      "\n",
      "\n",
      "Training Neural Network with NER features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\20100\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\20100\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\20100\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\20100\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\20100\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\20100\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\20100\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\20100\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy for Neural Network:\n",
      "0.2161836113037971\n",
      "Test Accuracy for Neural Network:\n",
      "0.21568154402895054\n",
      "Percision for Neural Network:\n",
      "0.21508140582562635\n",
      "Recall for Neural Network:\n",
      "0.21568154402895054\n",
      " Classification Report for Neural Network:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.00      0.00      1195\n",
      "           1       0.24      0.43      0.31      2000\n",
      "           2       0.00      0.00      0.00      1266\n",
      "           3       0.18      0.01      0.01      2000\n",
      "           4       0.26      0.23      0.24      2000\n",
      "           5       0.41      0.01      0.01      1267\n",
      "           6       0.21      0.04      0.07      1015\n",
      "           7       0.18      0.03      0.06      1863\n",
      "           8       0.20      0.42      0.27      1974\n",
      "           9       0.20      0.65      0.31      2000\n",
      "\n",
      "    accuracy                           0.22     16580\n",
      "   macro avg       0.22      0.18      0.13     16580\n",
      "weighted avg       0.22      0.22      0.15     16580\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "def create_pipeline(model):\n",
    "    return Pipeline([\n",
    "        ('classifier', model)\n",
    "    ])\n",
    "\n",
    "# Models\n",
    "models = {\n",
    "    'SVM': SVC(kernel='linear',C=2),\n",
    "    'Naive Bayes': MultinomialNB(alpha=0.5),\n",
    "    'Neural Network': MLPClassifier(hidden_layer_sizes=(50,25), activation='relu', solver='adam', max_iter=300, alpha=0.001)\n",
    "}\n",
    "\n",
    "output_dir = \"NER_New_Models/\"\n",
    "\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\nTraining {model_name} with NER features...\")\n",
    "    \n",
    "    \n",
    "    model_pipeline = create_pipeline(model)\n",
    "    \n",
    "    # Train the model\n",
    "    model_pipeline.fit(X_train_ner_vectorizer, train_df['category'])\n",
    "\n",
    "    # Make predictions on the train set\n",
    "    y_pred_train = model_pipeline.predict(X_train_ner_vectorizer)\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    y_pred_test = model_pipeline.predict(X_test_ner_vectorizer)\n",
    "\n",
    "    # Train Accuracy \n",
    "    print(f\"Train Accuracy for {model_name}:\")\n",
    "    print(accuracy_score(train_df['category'], y_pred_train))\n",
    "    \n",
    "    # Test Accuracy\n",
    "    print(f\"Test Accuracy for {model_name}:\")\n",
    "    print(accuracy_score(test_df['category'], y_pred_test))\n",
    "\n",
    "    # Percision Score\n",
    "    print(f\"Percision for {model_name}:\")\n",
    "    print(precision_score(test_df['category'], y_pred_test,average='weighted'))\n",
    "    \n",
    "    # Recall Score \n",
    "    print(f\"Recall for {model_name}:\")\n",
    "    print(recall_score(test_df['category'], y_pred_test,average='weighted'))\n",
    "\n",
    "    # Classification Report \n",
    "    print(f\" Classification Report for {model_name}:\")\n",
    "    print(classification_report(test_df['category'], y_pred_test))\n",
    "    \n",
    "    # Save Model\n",
    "    model_file_path = f\"{output_dir}{model_name}_ner_new_model.pkl\"\n",
    "    joblib.dump(model_pipeline, model_file_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `NER Words Only`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training SVM with NER features...\n",
      "Train Accuracy for SVM:\n",
      "0.6473293723798896\n",
      "Test Accuracy for SVM:\n",
      "0.41079613992762365\n",
      "Percision for SVM:\n",
      "0.5122209709613632\n",
      "Recall for SVM:\n",
      "0.41079613992762365\n",
      " Classification Report for SVM:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.23      0.30      1195\n",
      "           1       0.56      0.43      0.49      2000\n",
      "           2       0.59      0.28      0.38      1266\n",
      "           3       0.24      0.15      0.19      2000\n",
      "           4       0.64      0.56      0.60      2000\n",
      "           5       0.56      0.28      0.38      1267\n",
      "           6       0.64      0.40      0.49      1015\n",
      "           7       0.69      0.44      0.54      1863\n",
      "           8       0.63      0.35      0.45      1974\n",
      "           9       0.22      0.81      0.35      2000\n",
      "\n",
      "    accuracy                           0.41     16580\n",
      "   macro avg       0.52      0.39      0.42     16580\n",
      "weighted avg       0.51      0.41      0.42     16580\n",
      "\n",
      "\n",
      "Training Naive Bayes with NER features...\n",
      "Train Accuracy for Naive Bayes:\n",
      "0.5132400398105981\n",
      "Test Accuracy for Naive Bayes:\n",
      "0.4019903498190591\n",
      "Percision for Naive Bayes:\n",
      "0.5359205142559148\n",
      "Recall for Naive Bayes:\n",
      "0.4019903498190591\n",
      " Classification Report for Naive Bayes:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.22      0.33      1195\n",
      "           1       0.61      0.50      0.55      2000\n",
      "           2       0.71      0.31      0.43      1266\n",
      "           3       0.33      0.17      0.22      2000\n",
      "           4       0.20      0.80      0.32      2000\n",
      "           5       0.61      0.29      0.39      1267\n",
      "           6       0.72      0.43      0.54      1015\n",
      "           7       0.69      0.51      0.59      1863\n",
      "           8       0.60      0.45      0.51      1974\n",
      "           9       0.49      0.21      0.30      2000\n",
      "\n",
      "    accuracy                           0.40     16580\n",
      "   macro avg       0.56      0.39      0.42     16580\n",
      "weighted avg       0.54      0.40      0.41     16580\n",
      "\n",
      "\n",
      "Training Neural Network with NER features...\n",
      "Train Accuracy for Neural Network:\n",
      "0.6677323038875652\n",
      "Test Accuracy for Neural Network:\n",
      "0.42575392038600723\n",
      "Percision for Neural Network:\n",
      "0.5109259378199552\n",
      "Recall for Neural Network:\n",
      "0.42575392038600723\n",
      " Classification Report for Neural Network:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.24      0.31      1195\n",
      "           1       0.56      0.44      0.49      2000\n",
      "           2       0.63      0.29      0.40      1266\n",
      "           3       0.26      0.13      0.17      2000\n",
      "           4       0.65      0.57      0.61      2000\n",
      "           5       0.55      0.32      0.41      1267\n",
      "           6       0.63      0.41      0.49      1015\n",
      "           7       0.66      0.48      0.56      1863\n",
      "           8       0.59      0.41      0.48      1974\n",
      "           9       0.23      0.80      0.36      2000\n",
      "\n",
      "    accuracy                           0.43     16580\n",
      "   macro avg       0.52      0.41      0.43     16580\n",
      "weighted avg       0.51      0.43      0.43     16580\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "def create_pipeline(model):\n",
    "    return Pipeline([\n",
    "        ('classifier', model)\n",
    "    ])\n",
    "\n",
    "# Models\n",
    "models = {\n",
    "    'SVM': SVC(kernel='linear',C=5),\n",
    "    'Naive Bayes': MultinomialNB(alpha=0.5),\n",
    "    'Neural Network': MLPClassifier(hidden_layer_sizes=(50,25), activation='relu', solver='adam', max_iter=300, alpha=0.001)\n",
    "}\n",
    "\n",
    "output_dir = \"NER_New_Models/\"\n",
    "\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\nTraining {model_name} with NER features...\")\n",
    "    \n",
    "    \n",
    "    model_pipeline = create_pipeline(model)\n",
    "    \n",
    "    # Train the model\n",
    "    model_pipeline.fit(X_train_ner_vectorizer2, train_df['category'])\n",
    "\n",
    "    # Make predictions on the train set\n",
    "    y_pred_train = model_pipeline.predict(X_train_ner_vectorizer2)\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    y_pred_test = model_pipeline.predict(X_test_ner_vectorizer2)\n",
    "\n",
    "    # Train Accuracy \n",
    "    print(f\"Train Accuracy for {model_name}:\")\n",
    "    print(accuracy_score(train_df['category'], y_pred_train))\n",
    "    \n",
    "    # Test Accuracy\n",
    "    print(f\"Test Accuracy for {model_name}:\")\n",
    "    print(accuracy_score(test_df['category'], y_pred_test))\n",
    "\n",
    "    # Percision Score\n",
    "    print(f\"Percision for {model_name}:\")\n",
    "    print(precision_score(test_df['category'], y_pred_test,average='weighted'))\n",
    "    \n",
    "    # Recall Score \n",
    "    print(f\"Recall for {model_name}:\")\n",
    "    print(recall_score(test_df['category'], y_pred_test,average='weighted'))\n",
    "\n",
    "    # Classification Report \n",
    "    print(f\" Classification Report for {model_name}:\")\n",
    "    print(classification_report(test_df['category'], y_pred_test))\n",
    "    \n",
    "    # Save Model\n",
    "    model_file_path = f\"{output_dir}{model_name}_ner_new_model.pkl\"\n",
    "    joblib.dump(model_pipeline, model_file_path)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
